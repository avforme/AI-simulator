#!/bin/bash

# AIPlanner - Deep Learning Financial Planner
# Copyright (C) 2018-2019 Gordon Irlam
#
# All rights reserved. This program may not be used, copied, modified,
# or redistributed without permission.
#
# This program is distributed WITHOUT ANY WARRANTY; without even the
# implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
# PURPOSE.

AIPLANNER_HOME=${AIPLANNER_HOME:-$HOME/aiplanner}

source $AIPLANNER_HOME/ai/helpers.bash

mkdir -p ~/aiplanner-data/train-results
cd ~/aiplanner-data/train-results

PARALLEL=Jobs
SCENARIO_ARGS="--master-stocks-model=iid --master-stocks-mean-reversion-rate=0 --master-no-observe-stocks-price --master-stocks-return=0.065 --master-stocks-volatility=0.174 --master-no-real-bonds --master-no-nominal-bonds --master-iid-bonds --master-iid-bonds-return=0.010 --master-iid-bonds-volatility=0.110 --master-no-bills --master-no-returns-standard-error --master-no-tax --master-static-bonds --master-fixed-real-bonds-rate=0.01 --master-fixed-nominal-bonds-rate=0.03 --master-real-short-rate-type=current --master-inflation-short-rate-type=current"
TRAINING_ARGS='--master-age-retirement=0 --master-guaranteed-income=[{"owner":"self","age":null,"payout":[5e3,5e5],"source_of_funds":"taxable","type":"Social_Security"}] --master-p-tax-free=0 --master-p-taxable-stocks=0 --master-p-taxable-iid-bonds=0'
GAMMA=6
TRAINING=bucket
TIMESTEPS=4000000
BATCH_SIZE=100000
for UNIT in single couple; do
    for SPIAS in no_spias-merton-bucket_ce_growth1.01_rew_to_go_lo-5e2_rel_ce50_entropy0_retired_dbss_tax_free0_taxable_stocks0; do # no_spias spias; do

        ARGS="$SCENARIO_ARGS"
        TRAINARGS="$TRAINING_ARGS --train-num-timesteps=$TIMESTEPS --train-batch-size=$BATCH_SIZE --train-entropy-coefficient=0"
        if [ $SPIAS = spias ]; then
            ARGS="$ARGS --master-nominal-spias"
        fi
        if [ $SPIAS = spias80 ]; then
            ARGS="$ARGS --master-nominal-spias --master-spias-permitted-from-age=200 --master-spias-at-age=80"
        fi
        if [ $SPIAS = spias_pctl70 ]; then
            ARGS="$ARGS --master-nominal-spias"
        fi

        EPISODE="$UNIT-$SPIAS-gamma$GAMMA-nonanneal"
        mkdir -p $EPISODE
        cd $EPISODE
        train_scenarios $TRAINING $UNIT $GAMMA $EPISODE "$ARGS $TRAINARGS --train-save-frequency=500000"
        cd ..
        wait
        for TS in 2000000 3000000 4000000; do
            mkdir -p $EPISODE-timesteps$TS
            cd $EPISODE-timesteps$TS
            if [ $TRAINING = specific ]; then
                for TD in 2.5e5 5e5 1e6 2e6; do
                    TF=aiplanner.gamma$GAMMA-retired65-guaranteed_income16e3-tax_deferrred$TD.tf
                    mkdir -p $TF
                    cd $TF
                    for FILE in ../../$EPISODE/$TF/{seed_*,params.txt}; do
                        ln -s $FILE 2> /dev/null
                    done
                    cd ..
                done
            elif [ $TRAINING = bucket ]; then
                for GIF in 0.0_0.1 0.1_0.3 0.3_1.0; do
                    TF=aiplanner.gamma$GAMMA-gi_fraction$GIF.tf
                    mkdir -p $TF
                    cd $TF
                    for FILE in ../../$EPISODE/$TF/{seed_*,params.txt}; do
                        ln -s $FILE 2> /dev/null
                    done
                    cd ..
                done
            elif [ $TRAINING = generic ]; then
                TF=aiplanner.gamma$GAMMA.tf
                mkdir -p $TF
                cd $TF
                for FILE in ../../$EPISODE/$TF/{seed_*,params.txt}; do
                    ln -s $FILE 2> /dev/null
                done
                cd ..
            fi
            CP=`expr $TS / $BATCH_SIZE`
            eval_scenarios $TRAINING $UNIT $GAMMA $EPISODE "$ARGS --checkpoint-name=checkpoint_$CP"
            #eval_scenarios $TRAINING $UNIT $GAMMA $EPISODE "$ARGS --checkpoint-name=checkpoint_$CP --ensemble"
            cd ..
        done
        wait

        # This following code won't work as restore is broken and changed experiment parameters are currently ignored by tune on restore.
        # NATS=1500000
        # ANNEALS="500000 1000000 1500000 2000000"
        # for ANNEAL in $ANNEALS; do
        #     EPISODE="$UNIT-$SPIAS-gamma$GAMMA-nonanneal$NATS-anneal$ANNEAL"
        #     mkdir -p $EPISODE
        #     cd $EPISODE
        #     CP=`expr $NATS / 4000`
        #     TS=`expr $NATS + $ANNEAL`
        #     train_scenarios generic $UNIT $GAMMA $EPISODE "$ARGS --train-restore-dir=../single-no_spias-gamma6-nonanneal/aiplanner.gamma6.tf --train-restore-checkpoint-name=checkpoint_$CP --train-num-timesteps=$TS --train-anneal-num-timesteps=$ANNEAL"
        #     cd ..
        # done
        # wait
        # for ANNEAL in $ANNEALS; do
        #     EPISODE="$UNIT-$SPIAS-gamma$GAMMA-nonanneal$NATS-anneal$ANNEAL"
        #     cd $EPISODE
        #     eval_scenarios generic $UNIT $GAMMA $EPISODE "$ARGS"
        #     cd ..
        # done
        # wait

        # TS=2000000
        # ANNEALS="0 100000 200000 400000"
        # for ANNEAL in $ANNEALS; do
        #     EPISODE="$UNIT-$SPIAS-gamma$GAMMA-anneal$ANNEAL-timesteps$TS"
        #     mkdir -p $EPISODE
        #     cd $EPISODE
        #     train_scenarios specific $UNIT $GAMMA $EPISODE "$ARGS --train-anneal-num-timesteps=$ANNEAL --train-num-timesteps=$TS"
        #     cd ..
        # done
        # wait
        # for ANNEAL in $ANNEALS; do
        #     EPISODE="$UNIT-$SPIAS-gamma$GAMMA-anneal$ANNEAL-timesteps$TS"
        #     cd $EPISODE
        #     eval_scenarios specific $UNIT $GAMMA $EPISODE "$ARGS"
        #     cd ..
        # done
        # wait

    done
    exit
done

echo `date` Done

exit

# PPO examining 4 scenarios (with 2m timestep evaluations):
#   batch_size=100000, entropy_coeff=1e-3, kl_target=1, optimizer_step_size=5e-5, optimizer_epochs=30, minibatch_size=128, lambda=1, anneal_num_timesteps=0
#   model was prior to tuneable stocks curvature
# timesteps,mean CE,CE stderr (typically 20 experiments)
# gamma=6 specific 2.5e5 single no-spias:
1000000,27141.532122,11.211862
2000000,27206.079839,4.808965
3000000,27232.146407,5.596441
4000000,27218.473246,7.722734
5000000,27226.940843,4.746282
6000000,27219.222059,6.661287
# gamma=6 specific   5e5 single no-spias:
1000000,35472.458452,17.010340
2000000,35541.241878,14.200865
3000000,35566.933734,11.121769
4000000,35569.977472,13.034212
5000000,35599.083056,12.960910
6000000,35605.684595,19.288496
# gamma=6 specific   1e6 single no-spias:
1000000,50276.879059,69.842187
2000000,50684.641252,60.190155
3000000,50647.743870,67.201960
4000000,50620.347223,64.823658
5000000,50674.701332,76.814125
6000000,50741.200447,111.217853
# gamma=6 specific   2e6 single no-spias:
1000000,74177.851710,233.260873
2000000,78155.170028,254.238761
3000000,78658.786315,210.772457
4000000,79055.510560,165.534292
5000000,79211.361832,148.667113
6000000,79423.942598,208.876369

#                                         0m anneal (insignificantly worse CE distribution if anneal)
#         gamma=1.5
#             anneal=0                -   1.1%  0.3%  0.0%  0.2%  0.0%  -0.1%   0.0%         1.5m non-anneal
#     generic  single  spias
#         gamma=6
#             anneal=0                -  -0.9%  0.6% -0.1% -0.5%  0.5%  -0.5%   0.7%         0.5m non-anneal
#             anneal=250k                      +1.0%                                         500k anneal
#             anneal=500k                      +1.5%
#             anneal=750k                      +0.3%
#             anneal=1m                        +0.7%
#
# ppo1
#     train_num_timesteps        500k   1m      2m      5m     10m       recommended timesteps
#     specific single no-spias     -   1.8%    0.7%    0.3%     ?                ?
#     specific single  spias       -   6.8%    2.0%    1.2%     ?                ?
#     specific couple no-spias     -   5.7%    4.4%    7.6%    3.5%              ?
#     specific couple  spias       -   6.0%    3.9%    6.9%    3.6%              ?
#     generic  single no-spias     -   4.1%    1.2%    0.1%     ?                2m
#     generic  single  spias       -   1.2%    5.9%    1.7%     ?                5m
#     generic  couple no-spias     -  10.9%    6.8%    6.4%    1.0%             10m
#     generic  couple  spias       -  10.0%    1.6%    4.9%    3.6%             10m+
# train_num_timesteps=5000000 IS THUS APPROPRIATE FOR A SPECIFIC INDIVIDUAL MODEL
#
# ppo1 5m/10m (single/couple) timestep generic results as a fraction specific results average of 4 scenarios (with 2m timestep evaluations):
#     single no-spias   98.7%
#     single  spias     95.9%
#     couple no-spias  100.7%
#     couple  spias    100.8%
# THUS IT WOULD APPEAR BETTER TO USE A GENERIC MODEL FOR A COUPLE, BUT TRAIN A SPECIFIC MODEL FOR AN INDIVIDUAL
#
# ppo1 5m/10m (single/couple) timestep no spias results as a fraction of spia results average of 4 scenarios (with 2m timestep evaluations):
#     specific single                   94.4%
#     specific couple  couple-spias    103.4%  5m timesteps; no probabilistic defined benefits
#     specific couple no-couple-spias   99.0%
#     generic  single                   97.2%
#     generic  couple  couple-spias    101.8%  5m timesteps; no probabilistic defined benefits
#     generic  couple no-couple-spias   98.8%
# couple_spias=False IS THUS THE DEFAULT
#
# ppo1 nominal_bonds_duration=15 improvement relative to duration=None average of 4 scenarios
#     (old couple model, no probabilistic defined benefits, 2m timesteps, and 2m timestep evaluation):
#     specific single no-spias    0.2%
#     specific single  spias      0.4%
#     specific couple no-spias    1.5%
#     specific couple  spias      2.3%
#     generic  single no-spias    1.1%
#     generic  single  spias     -0.7%
#     generic  couple no-spias    1.0%
#     generic  couple  spias      1.3%
# nominal_bonds_duration=15 IS THUS THE DEFAULT
#
# ppo1:
#     Specific gamma for variable scenario performs 2-3% worse than specific scenario.
#     Generic gamma for variable scenario perform 2-3% worse than specific gamma for variable scenario.
#
# Notes on ppo1 tweaks that have been tried out (single with no nominal SPIAs):
#
# --train-hidden-layer-size=128
#    Produced 0.2% worse generic results than hidden layer size 64 both pposgd_simple.learn(optim_batchsize=64).
#
# --train-hidden-layer-size=128 --train-single-num-timesteps=2000000
#    Produced 0.6% worse generic results than 1m timesteps and hidden layer size 64 both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(lam=0.98)
# pposgd_simple.learn(lam=1)
#    Produced 0.2% better and 0.1% worse generic results than lam=0.95 all pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_batchsize=128)
# pposgd_simple.learn(optim_batchsize=256)
#    Produced 0.3% better and 0.3% generic results than optim_batchsize=64.
#    WE NOW DEFAULT TO AN optim_batchsize of 128 COMPARED TO THE ORIGINAL VALUE OF 64.
#
# pposgd_simple.learn(adam_epsilon=1e-6)
#    Produced 0.1% worse generic results than adam_epsilon=1e-5 default both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_epochs=20)
#    Produced 0.4% worse generic results than optim_epochs=10 both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_batchsize=128, optim_stepsize=3e-5)
#    Produduced 0.4% worse generic results than optim_batchsize=128, optim_stepsize=3e-4.
#
# pposgd_simple.learn(optim_batchsize=128, optim_stepsize=1e-4)
#    Produduced 0.2% worse generic results than optim_batchsize=128, optim_stepsize=3e-4.
#
# --train-num-hidden-layers=3
#    Produced 0.4% worse generic results than 2 hidden layers both pposgd_simple.learn(optim_batchsize=128)
#
# Notes on PPO1 tweaks that have been tried out (couple with no nominal SPIAs):
#
# --train-num-timesteps=5000000 --eval-consume-clip=5000
#    Produced identical results to eval_consume_clip=0.
#
# Notes on PPO1 tweaks that have been tried out (couple with no nominal SPIAs and nomnal_bonds_duration15):
#
# optim_epochs=50
#    Produced 9.9% worse generic results than optim_epochs=10.
#
# optim_stepsize=1e-4
#    Produced 9.7% worse generic results than optim_stepsize=3e-4.
#
# --train-miniibatch-size=512
#    Produced 11.6% worse generic results than train_minibatch_size=128.
#
# timesteps_per_actor_batch=8192
#    Produced 8.8% worse results than timesteps_per_actor_batch=2048, but with around 1/3 the CE standard deviation.
#
# timesteps_per_actor_batch=8192 --train-num-timesteps=5000000
#    Produced 2.0% worse results than timesteps_per_actor_batch=2048 --train-num-timesteps=2000000, with similar CE standard deviaiton, but no failed runs.
#
# Notes on PPO1 tweaks that have been tried out (single/couple with nominal SPIAs):
#
# --master-nominal-spias --train-single-num-timesteps=2000000 --hidden-layer-size=128
#    Produced 3.0% worse generic results than size 64.
#
# --master-sex2=male --master-nominal-spias --train-num-timesteps=2000000
#    Produced 3.0% worse generic results than --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --no-train-couple-net
#    Produced 10.3% worse generic results than the default, --train-couple-net.
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --master-gamma=3
#    Produced 8.4% worse generic results than variable gamma.
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --master-nomal-bonds-duration=15
#    Produced 3.4% better generic results than variable bonds duration.
