#!/bin/bash

# AIPlanner - Deep Learning Financial Planner
# Copyright (C) 2018 Gordon Irlam
#
# All rights reserved. This program may not be used, copied, modified,
# or redistributed without permission.
#
# This program is distributed WITHOUT ANY WARRANTY; without even the
# implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
# PURPOSE.

AIPLANNER_HOME=${AIPLANNER_HOME:-$HOME/aiplanner}

source $AIPLANNER_HOME/ai/helpers.bash

mkdir -p results
cd results

PARALLEL=Jobs
ALGORITHM=ppo1
GAMMA=3 # train_eval currently only generates models with a gamma of 3.
for TIMESTEPS in 500000 1000000 2000000 5000000; do
    for UNIT in single couple; do
        for SPIAS in no_spias spias; do

            TRAINARGS="--train-num-timesteps=$TIMESTEPS"
            ARGS=""
            if [ $SPIAS = spias ]; then
                ARGS="$ARGS --master-nominal-spias"
            fi

            EPISODE="$ALGORITHM-$UNIT-$SPIAS-gamma$GAMMA-timesteps$TIMESTEPS"

            mkdir -p $EPISODE
            cd $EPISODE

            if [ $ALGORITHM == ppo1 ]; then
                TRAINER="$AI_DIR/train_ppo1.py"
            else
                TRAINER="$AI_DIR/train_spinup.py --train-algorithm=$ALGORITHM"
            fi
            TRAINER="$TRAINER $TRAINARGS $ARGS"
            EVALUATOR="$AI_DIR/eval_model.py $ARGS"

            if [ $UNIT = single ]; then
                train_eval_single $EPISODE
            else
                train_eval_couple $EPISODE
            fi

            cd ..

        done
    done
done

echo `date` Done

# PPO1 average improvement relative to prior timesteps average of 4 scenarios (with 2m timestep evaluations):
#     train_num_timesteps        500k   1m      2m      5m     10m
#     specific single no-spias     -   1.8%    0.7%    0.3%     ?
#     specific single  spias       -   6.8%    2.0%    1.2%     ?
#     specific couple no-spias     -   5.7%    4.4%    7.6%    3.5%
#     specific couple  spias       -   6.0%    3.9%    6.9%    3.6%
#     generic  single no-spias     -   4.1%    1.2%    0.1%     ?
#     generic  single  spias       -   1.2%    5.9%    1.7%     ?
#     generic  couple no-spias     -  10.9%    6.8%    6.4%    1.0%
#     generic  couple  spias       -  10.0%    1.6%    4.9%    3.6%
# train_num_timesteps=5000000 IS THUS APPROPRIATE FOR A SPECIFIC INDIVIDUAL MODEL
#
# PPO1 5m/10m (single/couple) timestep generic results as a fraction specific results average of 4 scenarios (with 2m timestep evaluations):
#     single no-spias   98.7%
#     single  spias     95.9%
#     couple no-spias  100.7%
#     couple  spias    100.8%
# THUS IT WOULD APPEAR BETTER TO USE A GENERIC MODEL FOR A COUPLE, BUT TRAIN A SPECIFIC MODEL FOR AN INDIVIDUAL
#
# PPO1 5m/10m (single/couple) timestep no spias results as a fraction of spia results average of 4 scenarios (with 2m timestep evaluations):
#     specific single                   94.4%
#     specific couple  couple-spias    103.4%  5m timesteps; no probabilistic defined benefits
#     specific couple no-couple-spias   99.0%
#     generic  single                   97.2%
#     generic  couple  couple-spias    101.8%  5m timesteps; no probabilistic defined benefits
#     generic  couple no-couple-spias   98.8%
# couple_spias=False IS THUS THE DEFAULT
#
# PPO1 nominal_bonds_duration=15 improvement relative to duration=None average of 4 scenarios
#     (old couple model, no probabilistic defined benefits, 2m timesteps, and 2m timestep evaluation):
#     specific single no-spias    0.2%
#     specific single  spias      0.4%
#     specific couple no-spias    1.5%
#     specific couple  spias      2.3%
#     generic  single no-spias    1.1%
#     generic  single  spias     -0.7%
#     generic  couple no-spias    1.0%
#     generic  couple  spias      1.3%
# nominal_bonds_duration=15 IS THUS THE DEFAULT
#
# PPO1:
#     Specific gamma for variable scenario performs 2-3% worse than specific scenario.
#     Generic gamma for variable scenario perform 2-3% worse than specific gamma for variable scenario.
#
# Notes on PPO1 tweaks that have been tried out (single with no nominal SPIAs):
#
# --train-hidden-layer-size=128
#    Produced 0.2% worse generic results than hidden layer size 64 both pposgd_simple.learn(optim_batchsize=64).
#
# --train-hidden-layer-size=128 --train-single-num-timesteps=2000000
#    Produced 0.6% worse generic results than 1m timesteps and hidden layer size 64 both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(lam=0.98)
# pposgd_simple.learn(lam=1)
#    Produced 0.2% better and 0.1% worse generic results than lam=0.95 all pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_batchsize=128)
# pposgd_simple.learn(optim_batchsize=256)
#    Produced 0.3% better and 0.3% generic results than optim_batchsize=64.
#    WE NOW DEFAULT TO AN optim_batchsize of 128 COMPARED TO THE ORIGINAL VALUE OF 64.
#
# pposgd_simple.learn(adam_epsilon=1e-6)
#    Produced 0.1% worse generic results than adam_epsilon=1e-5 default both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_epochs=20)
#    Produced 0.4% worse generic results than optim_epochs=10 both pposgd_simple.learn(optim_batchsize=64).
#
# pposgd_simple.learn(optim_batchsize=128, optim_stepsize=3e-5)
#    Produduced 0.4% worse generic results than optim_batchsize=128, optim_stepsize=3e-4.
#
# pposgd_simple.learn(optim_batchsize=128, optim_stepsize=1e-4)
#    Produduced 0.2% worse generic results than optim_batchsize=128, optim_stepsize=3e-4.
#
# --train-num-hidden-layers=3
#    Produced 0.4% worse generic results than 2 hidden layers both pposgd_simple.learn(optim_batchsize=128)
#
# Notes on PPO1 tweaks that have been tried out (couple with no nominal SPIAs):
#
# --train-num-timesteps=5000000 --eval-consume-clip=5000
#    Produced identical results to eval_consume_clip=0.
#
# Notes on PPO1 tweaks that have been tried out (couple with no nominal SPIAs and nomnal_bonds_duration15):
#
# optim_epochs=50
#    Produced 9.9% worse generic results than optim_epochs=10.
#
# optim_stepsize=1e-4
#    Produced 9.7% worse generic results than optim_stepsize=3e-4.
#
# --train-miniibatch-size=512
#    Produced 11.6% worse generic results than train_minibatch_size=128.
#
# timesteps_per_actor_batch=8192
#    Produced 8.8% worse results than timesteps_per_actor_batch=2048, but with around 1/3 the CE standard deviation.
#
# timesteps_per_actor_batch=8192 --train-num-timesteps=5000000
#    Produced 2.0% worse results than timesteps_per_actor_batch=2048 --train-num-timesteps=2000000, with similar CE standard deviaiton, but no failed runs.
#
# Notes on PPO1 tweaks that have been tried out (single/couple with nominal SPIAs):
#
# --master-nominal-spias --train-single-num-timesteps=2000000 --hidden-layer-size=128
#    Produced 3.0% worse generic results than size 64.
#
# --master-sex2=male --master-nominal-spias --train-num-timesteps=2000000
#    Produced 3.0% worse generic results than --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --no-train-couple-net
#    Produced 10.3% worse generic results than the default, --train-couple-net.
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --master-gamma=3
#    Produced 8.4% worse generic results than variable gamma.
#
# --master-sex2=male --master-nominal-spias --train-single-num-timesteps=2000000 --train-couple-num-timesteps=2000000 --master-nomal-bonds-duration=15
#    Produced 3.4% better generic results than variable bonds duration.
