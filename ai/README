AIPlanner - Deep Reinforcement Learning Financial Planner
=========================================================

Tensorflow
----------

Tensorflow is the deep learning framework used. I would like to run on
Ubuntu 18.04, but Ubuntu 18.04 has CUDA 9.1.  Google won't be
releasing tensorflow for CUDA 9.1, will release for 9.2. Would thus
need to manually install CUDA, which based on the tensorflow docs, is
messy.

Hence for time being using Amazon's Deep Learning AMI (Ubuntu)
currently based on Ubuntu 16.04 - CUDA 9 - with tensorflow
pre-installed.

     Region    Deep Learning Version          AMI
    us-east-1           21.2          ami-0d96d570269578cd7
    us-east-2           21.2          ami-0a47106e391391252

For this instance 150G of storage is recommended. The default of 75G
only leaves 5G for AIPlanner.

Server requirements
-------------------

AIPlanner runs well in production on an 2 core 4 thread 16G RAM Amazon
m5.xlarge instance (ideally want 3 cores and at least 16G of
RAM). Training the neural network requires running around 10 c5.4xlarge
spot instances for 2-3 days. The us-east-2 region currently
appears the cheapest region for performing this training work.

For development a much smaller m5.large, or even a t3.small instance,
can often be used, provided in the first case a Ray compute cluster is
configured, or in the second case the SEEDS=1 environment variable is
set and the --train-seeds=1 flag is passed to api/server.py .

For deployment on the Internet the machine will need to have ports 80
and 443 open (http and https), along with 20 (ssh) for administrative
access. An elastic IP will need to be associated with the machine.
And www.<thisdomain> and <thisdomain> should be CNAMES/A records for
the elastic IP's public DNS name/address respectively.

For deployment on an Intranet only ports 443 and 20 are required.
Creating a CNAME for the private DNS name is probably also desirable.

Set up hostname
---------------

This step is optional. It helps when using EC2 to give various
instances meaningful names.

sudo bash
echo <unqualified-hostname> > /etc/hostname
hostname -F /etc/hostname
[edit] /etc/hosts
modify: 127.0.0.1 localhost <unqualified-hostname>
exit

Obtain the source
-----------------

Set up an EC2 instance with tensorflow, ssh in to it, and obtain the
sources:

    cd ~
    git clone https://github.com/gordoni/aiplanner.git

Obtaining additional required components
----------------------------------------

Installing additional required components on Ubuntu 18.04 (currently
not workable):

    sudo
    apt install catdoc gnuplot-nox python3-pip python3-dev python3-mpi4py nodejs npm
    apt install python3-boto3
    pip3 install tensorflow
    pip3 install gym
    pip3 install 'ray[debug]==0.7.3'
    exit

Installing additional required components on Amazon's Deep Learning
AMI (Ubuntu):

    sudo apt install catdoc gnuplot-nox
    source activate tensorflow_p36
    pip install arch --install-option='--no-binary'
        # only needed if you wish to fit your own volatility model
    #pip install mpi4py # only needed if using OpenAI baselines
    #pip install joblib # only needed if using OpenAI baselines
    pip install gym
    pip install 'ray[debug]==0.7.3'
    pip install opencv-python-headless # not needed if using Deep Learning AMI 24.0

Hack Ray to use our version of RLlib, not the default version:

    RAY=`pip show ray | grep Location | awk '{print $2}'`/ray
    mv $RAY/rllib $RAY/rllib.old
    ln -s ~/aiplanner/ai/ray/python/ray/rllib $RAY/rllib

Note, you may need to disable this link if upgrading Ray to prevent
pip clobbering the repository.

If plan to deploy the web UI then install the required components for
the Angular website:

    [ Get latest Node.js per https://nodejs.org/en/download/ ]
    cd ~
    curl https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz | tar xJf -
    export PATH=$HOME/node-v10.16.3-linux-x64/bin:$PATH

npm install -g typescript
npm install -g @angular/cli

Cache the interest rate data
----------------------------

Failing to perform this step will result in the full historical yield
curves getting downloaded from the Fed every time a cluster node
starts up.

    mkdir ~/aiplanner-data
    ~/aiplanner/ai/cron.daily

Setting up the Ray compute cluster
----------------------------------

This step is optional.

A Ray compute cluster can be used to train the neural network models
on cheaper spot instances rather than on demand instances.

The cluster works most effectively if the head node and worker nodes
are of similar instance families. Otherwise jobs will execute at
uneven rates.

Create a cluster config file:

    cd ~/aiplanner/ai
    cp cluster-example.yaml cluster.yaml
    [edit] cluster.yaml
        # Alter worker_nodes:InstanceType if desired.
        # For maximum performance add --num-cpus=<num_cores> to
        #     ray start in worker_start_ray_commands.
        #     c5.4xlarge has 8 cores, but setting --num-cpus=10 is
        #     probably better for playing around as typically train
        #     10 models in parallel.
        # Other changes as desired.

Rather than have separate cluster head and worker nodes, we are going
to have the AIPlanner host act as the head node. This allows the web
server and jobs that use Ray to share result data directories, but it
requires a little fancy footwork.

First create the cluster IAM role, ssh key pair, and security group.

The easy way to do this is risky as it involves giving full access to
AWS to untrusted code. This may be acceptable if you don't have any
other AWS resources.

If you wish to use the easy risky way, place your AWS credentials in
~/.aws/credentials as described in the boto3 docs.

-----
[default]
aws_access_key_id=<aws_access_key_id>
aws_secret_access_key=<aws_secret_access_key>
-----

    cd ~/aiplanner/ai
    ray up cluster.yaml
    <answer NO to "create new cluster">

This will create the ssh key pair, IAM role, and network security
group.

If you wish to use the difficult but secure method, first use EC2 to
generate an EC2 key pair called ray-autoscaler_us-east-2.pem, and save
it to the .ssh directory of the AIPlanner host. Then create a security
group tagged ray-autoscaler-default that allows all inbound traffic
from itself, inbound ssh from the Internet if desired, and all
outbound traffic. Finally generate an EC2 IAM role named
ray-autoscaler-v1 with the following inline IAM policy attached (in
which sg-AAA is replaced by the ray-autoscaler-default security group;
use multiple security-group lines if have more than one region):

{"Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowRunInstancesTagged",
            "Effect": "Allow",
            "Action": [
                "ec2:RunInstances"
            ],
            "Resource": "arn:aws:ec2:*:*:instance/*",
            "Condition": {
                "ForAnyValue:StringLike": {
                    "aws:RequestTag/Name": "ray-default-*"
                }
            }
        },
        {
            "Sid": "AllowRunInstances",
            "Effect": "Allow",
            "Action": "ec2:RunInstances",
            "Resource": [
                "arn:aws:ec2:*:*:subnet/*",
                "arn:aws:ec2:*:*:security-group/sg-AAA",
                "arn:aws:ec2:*:*:volume/*",
                "arn:aws:ec2:*:*:network-interface/*",
                "arn:aws:ec2:*::image/*",
                "arn:aws:ec2:*:*:key-pair/*"
            ]
        },
        {
            "Sid": "AllowCreateTagsWhenLaunching",
            "Effect": "Allow",
            "Action": [
                "ec2:CreateTags"
            ],
            "Resource": [
                "arn:aws:ec2:*:*:instance/*",
                "arn:aws:ec2:*:*:volume/*"
            ],
            "Condition": {
                "StringEquals": {
                    "ec2:CreateAction": "RunInstances"
                }
            }
        },
        {
            "Sid": "AllowActionTaggedInstances",
            "Effect": "Allow",
            "Action": [
                "ec2:TerminateInstances",
                "ec2:CreateTags"
            ],
            "Resource": "arn:aws:ec2:*:*:instance/*",
            "Condition": {
                "StringLike": {
                    "ec2:ResourceTag/Name": "ray-default-*"
                }
            }
        },
        {
            "Sid": "AllowDescribe",
            "Effect": "Allow",
            "Action": [
                "ec2:DescribeInstances",
                "ec2:DescribeSecurityGroups",
                "ec2:DescribeSubnets"
            ],
            "Resource": "*"
        },
        {
            "Sid": "AllowGetInstanceProfile",
            "Effect": "Allow",
            "Action": [
                "iam:GetInstanceProfile"
            ],
            "Resource": "arn:aws:iam::*:instance-profile/ray-autoscaler-v1"
        }
    ]
}

You may wish to further harden things by restricting the AWS image
that can be used.

Either way the required AWS resources have now been
created. Additional work is required so that the AIPlanner host can
act as the head node.

From the EC2 console perform actions on this host setting the instance
setting IAM role to ray-autoscaler-v1 and networking change security
groups to add ray-autoscaler-default.

For syncing worker node result directories create a link:

    ln -s ~/.ssh/ray-autoscaler_us-east-2.pem ~/ray_bootstrap_key.pem

To the "worker_nodes" section of cluster.yaml add:

----
    SubnetIds:
        - subnet-AAA
    SecurityGroupIds:
        - sg-AAA
----

where the subnet is the subnet in which you wish to create worker
nodes, and the security group identifies ray-autoscaler-default.

If desired, the cluster can now be manually started using:

    cd ~/aiplanner/ai
    source activate tensorflow_p36
    ray start --head --redis-port=6379 --autoscaling-config=cluster.yaml

Worker nodes are created when needed, and terminated if idle for a
while.

The cluster can be torn down using:

    cd ~/aiplanner/ai
    ray stop
        # Stops Ray on the head node.
    ray down cluster.yaml
        # Terminates any running worker nodes.

A dedicated worker AMI image can be created to speed up the cluster
start up process. To do this temporarily set min_workers to 1 in
cluster.yaml and then start up the head node as above. From the EC2
console select the instance and perform action - image - create image.
Update the worker_nodes ImageId with the newly create AMI id.

Setting up environment variables
--------------------------------

Various environment variables need to be set up for production or
development tasks:

    source activate tensorflow_p36

If you have set up a Ray compute cluster indicate you want to use it
during training:

    export RAY_AUTOSCALER=True

You can also specify:

    export RAY_AUTOSCALER_USE_HEAD=False

This will prevent running any of the training on the head node. The
reason you may want to do this is the head node will likely be slower
than the worker nodes because it is also running the Ray monitor
process. This slows the training of multiple neural networks in
parallel. The reason you may not want to do this is if you do it there
will then always be at least one worker node running, even when Ray is
otherwise idle. This can increase the financial cost of the resources
used.

Fit the equity volatility model
-------------------------------

A bootstrapped equity return model with GJR-GARCH volatility is
typically used. The model has already been fitted, but if you wish to
fit it yourself perform the following steps.

    cd ~/aiplanner
    mkdir -p data/public
    mkdir -p data/private/ticker
    [download the max time period ticker data for ^SP500TR and ^GSPC
     from https://finance.yahoo.com and store it in the just created
     directory as ^SP500TR.csv and ^GSPC.csv ]
    cd ~/aiplanner/ai/equity_model
    ./run
    cp standardized_residuals.csv ../../data/public
    [and use the just determined --stocks-* parameters when training
     and evaluating]

Training the generic nueral network models
------------------------------------------

Unless you plan on serving pre-trained neural network models you will
need to train the neural network models.

Training the neural network models (will take 2-3 days on around 10
InstanceType c5.4xlarge instances with Ray started with --num-cpus=8;
edit cluster.yaml accordingly; many smallish instances are preferable
to a few very large instances as Amazon seems more likely to reclaim
very large spot instances slowing the training process):

    cd ~/aiplanner/ai/api
    nohup ./train > /tmp/train.out &

Training logs will be written to /tmp/train* . Progress can be
monitored using a command similar to:

    tail -f /tmp/train* | grep seed

Note that any AIPlanner warnings from a single model's training get
duplicated across all log files.

The trained models will be placed in ~/aiplanner-data/models.new .

By default the trained models will be served without any adjustments
for model biases. If you know the model is biased it is possible to
apply corrections when serving that attempt to overcome the model
bias:

    [edit] ~/aiplanner-data/models.new/models-adjust.json

See ~/aiplanner/ai/models-adjust-example.json for typical adjustments
to apply, or perhaps simply copy this file to the above.

The models should then be installed:

    cd ~/aiplanner-data
    rm -rf models.old # Delete prior model backups if required.
    mv models models.old # Save prior models if any as a backup.
    mv models.new models

Finally, the market price and volatility levels should be updated:

    ~/aiplanner/ai/cron.weekly

Generating required assets for the UI website (images)
------------------------------------------------------

Both of the UI website sections can be skipped if you only wish to run
the AIPlanner API server.

Generate the images required for the UI website:

    cd ~/aiplanner/ai/angular/src/assets.generate
    ./run

Build the UI website files
--------------------------

Angular provides a single webpage app for interacting with the models.

Install the Angular builder:

    export PATH=$HOME/node-v10.16.3-linux-x64/bin:$PATH
    cd ~/aiplanner/ai/angular
    npm ci @angular-devkit/build-angular

Angular downloads 500MB of node modules in order to build the website.
These files would slow down the process of synchronizing source trees
when starting up a new Ray cluster node. Therefore if Ray is used it
is recommended that the node modules be stored outside the source
tree:

    cd ~/aiplanner/ai/angular
    mv node_modules ~/
    ln -s ~/node_modules ~/aiplanner/ai/angular/

Build the website:

    export PATH=$HOME/node-v10.16.3-linux-x64/bin:$PATH
    cd ~/aiplanner/ai/angular
    ng build --prod

Install the website:

    cd ~/aiplanner/ai/angular
    ./install

Set up the web server
---------------------

Even if only running the API server, you may wish to set up a
webserver. In this case the webserver will be responsible for proxying
/api TLS requests on port 443 to the API server.  If you don't intend
to use TLS internally for talking to the API server you can skip this
section and have applications connect to the API server directly
withoout encryption, either on the default port (3000), or the http
port (80) by adding the argument "--port 80" when installing the
aiplanner-apiserver.service file later.

    sudo apt install apache2
    sudo a2enmod ssl proxy proxy_http
    sudo service apache2 restart

    Select appropriate <site-ssl.conf> file:
        sudo cp aiplanner/ai/web/sites-examples/<sample-site-ssl.conf> /etc/apache2/sites-available/<site-ssl.conf>
    Edit site.conf appropriately:
        sudo <edit> /etc/apache2/sites-available/<site-ssl.conf>

    Repeat installing <site.conf> or <site-ssl.conf> for additional
    sites to be served if desired, so that http://www.<site>/,
    http://<site>/, and https://<site>/ will all point to
    https://www.<site>/.

    Enable each plain <site.conf> (but not the <site-ssl.conf>s):
        sudo a2ensite <site>

    Ubuntu 18.04:
        sudo apt install python3-certbot-apache
    Ubuntu 16.04:
        sudo add-apt-repository ppa:certbot/certbot
        sudo apt update
            # Ignore the nvidia package errors.
        sudo apt install python3-certbot-apache
    sudo certbot --apache certonly
        # Add "--domains <thisdomain>" to force a particular domain.
    Email: <you@yourdomain>
    Domains: 
        If serving for www.<thisdomain> then typically: <thisdomain>, www.<thisdomain>
        If serving for a particular host: <thishost.thisdomain>

    Enable each <site-ssl.conf>:
        sudo a2ensite <site-ssl>

    sudo service apache2 reload

Set up the aiplanner system configuration file
----------------------------------------------

    cd ~/aiplanner/ai
    cp aiplanner-example.yaml ~/aiplanner-data/aiplanner.yaml
    sudo [edit] ~/aiplanner-data/aiplanner.yaml
        # Possibly change port to 80 if running the api server within an Intranet
        # Set notify_email to the address that will send notifications notify@<thisdomain>
        # Set admin_email to the address that will receive notifications <you@yourdomain>

Configure systemd to start the api server upon booting
------------------------------------------------------

Set up the systemd config:

    cd ~/aiplanner/ai
    sudo cp aiplanner-apiserver.service /etc/systemd/system/
    sudo systemctl enable aiplanner-apiserver

Start the service up:

    sudo systemctl start aiplanner-apiserver

Setup the backend web server
----------------------------

The backend web server responds to requests for web related services
from the website. Curretly this only comprises handling email
subscription requests.

Set up the systemd config:

    cd ~/aiplanner/ai
    sudo cp aiplanner-webserver.service /etc/systemd/system/
    sudo systemctl enable aiplanner-webserver

Start the service up:

    sudo systemctl start aiplanner-webserver

Setting up cron
---------------

Install crontabs to perform a daily refresh of the interest rate yield
curves, and a weekly refresh of the fair market price and volatility.

    crontab -e

----
# m h  dom mon dow   command
MAILTO=<you@yourdomain>
0 0 * * * perl -e '{sleep(rand(1000))}'; ~/aiplanner/ai/cron.daily
0 0 * * 0 perl -e '{sleep(rand(1000))}'; ~/aiplanner/ai/cron.weekly
----

Seting up log rotation
----------------------

    sudo chmod g-w ~/aiplanner-data/ # Required by logrotate.

    cd ~/aiplanner/ai
    sudo cp aiplanner.logrotate /etc/logrotate.d/aiplanner

Installing an outbound mailer
-----------------------------

A mail transfer agent is only required to provide system notification
messages to the administrator. These are api server request error
messages and sign up subscription notifications generated by users of
the web UI.

    sudo apt install postfix
        # Any choices here are fine as we are about to reconfigure.
    sudo dpkg-reconfigure postfix
        Config type: Internet Site
        Site: <thisdomain>
        Root mail: <you@yourdomain>
        Accept mail for: <thisdomain>
        Synchronous updates: no
        Local networks: <leave as is>
        Mailbox size limit: 0
        Address extension: +
        Internet protocols: all
    sudo <edit> /etc/postfix/main.cf
        Change: myhostname = <...>
        To: myhostname = <thisdomain>
    sudo /etc/init.d/postfix reload

You may also need to add an SPF record for the site so messages from
it don't end up in the spam folder. Something like:

    Type: TXT
    Host: @
    Value: v=spf1 ip4:18.206.41.110 ~all
    TTL: 3600

Inbound mail flow isn't really required, but if you wish to enable
it follow the remaining steps.

You can add a MX record so the server can receive and forward bounce
messages addressed to root. Something like:

    Type: MX
    Host: @
    Priority: 1
    Value: ec2-18-206-41-110.compute-1.amazonaws.com
    TTL: 3600

Consult your domain provider for details of how to do these steps.

Finally you can create a firewall rule to allow inbound SMTP
connections on port 25. Consult your service provider for details.

Performing site health checks
-----------------------------

For a production website Uptime robot, or some other service should be
used to perform periodic HTTPS GET /web/healthcheck and
/webapi/healthcheck requests to port 443 of the production server.
After about 1 second, the string "OK" should be returned as the body
to indicate the system appears to be operating normally, any other
result indicates a problem.

For a production api server HTTP GET /api/healthcheck requests should
be used.

Building an api server docker container
---------------------------------------

The api server may be distributed as a docker container.

    cd ~/aiplanner/ai/ray
    ./build-docker.sh --skip-examples

    TBD

Development
-----------

The api server has three functions:
    - respond to the Angular server proxying to it to handle HTTP /api requests
    - purge old results from the directory ~/aiplanner-data/results
    - respond to HTTP /api/healthcheck requests

The api server can be run in development as follows:

    cd ~/aiplanner/ai/api
    # First stop any production apiserver
    systemctl --user stop aiplanner-apiserver
    # Then start up the development apiserver
    ./server.py

On the same machine in another shell window run the Angular server:

    export PATH=$HOME/node-v10.16.3-linux-x64/bin:$PATH
    cd ~/aiplanner/ai/angular
    ng serve --host 0.0.0.0 --public-host <thishost.thisdomain>

Ignore the circular dependency warning.

Connect to the front end using a browser (need to open port 4200 of
development machine firewall unless doing development on localhost):

    http://<thishost.thisdomain>:4200/
