AIPlanner - Deep Reinforcement Learning Financial Planner.

Server requirements
-------------------

AIPLanner runs well in production on an 8 core 16 thread Amazon
c5.4xlarge instance. Such an instance is also necessary for training
the generic neural networks.

For development a much smaller c5.large, or even a t3.small instance,
can often be used, provided in the first case a Ray compute cluster is
configured or in the second case the SEEDS=1 environment variable is
set and the --num-models=1 flag is passed to web/server .

Tensorflow
----------

Tensorflow is the deep learning framework used. Would like to run on
Ubuntu 18.04, but Ubuntu 18.04 has CUDA 9.1.  Google won't be
releasing tensorflow for CUDA 9.1, will release for 9.2. Would thus
need to manually install CUDA, which based on the tensorflow docs, is
messy.

Hence for time being using Amazon's Deep Learning AMI (Ubuntu) Version
21.2 based on Ubuntu 16.04 - CUDA 9 - with tensorflow pre-installed.
In the us-east-1 region this is AMI ami-0d96d570269578cd7. For this
instance 100G of storage is recommended. The default of 75G only
leaves 8G for AIPlanner.

Set up hostname
---------------

This step is optional. It helps when using EC2 to give various
instances meaningful names.

sudo bash
echo <unqualified-hostname> > /etc/hostname
hostname -F /etc/hostname
[edit] /etc/hosts
modify: 127.0.0.1 localhost <unqualified-hostname>
exit

Obtain the source
-----------------

Set up an EC2 instance with tensorflow, ssh in to it, and obtain the
sources:

    cd ~
    git clone <aiplanner-repository> aiplanner
    cd ~/aiplanner
    git checkout ai

Obtaining additional required components
----------------------------------------

Installing additional required components on Ubuntu 18.04 (currently
not workable):

    sudo
    apt install catdoc gnuplot-nox python3-pip python3-dev python3-mpi4py nodejs npm
    apt install python3-boto3
    pip3 install tensorflow
    pip3 install gym
    pip3 install ray==0.6.4
    exit

Installing additional required components on Amazon's Deep Learning
AMI (Ubuntu):

    sudo apt install catdoc gnuplot-nox
    source activate tensorflow_p36
    pip install arch --install-option='--no-binary'
        # only needed if you wish to fit your own volatility model
    #pip install mpi4py # only needed if using OpenAI baselines
    #pip install joblib # only needed if using OpenAI baselines
    pip install gym
    pip install ray==0.6.4

Hack Ray to use our version of RLlib, not the default version:

    RAY=`pip show ray | grep Location | awk '{print $2}'`/ray
    mv $RAY/rllib $RAY/rllib.old
    ln -s ~/aiplanner/ai/ray/python/ray/rllib $RAY/rllib

Note, you may need to disable this link if upgrading Ray to prevent
pip clobbering the repository.

If you plan to use a Ray compute cluster (described later), you may
need to install the following additional packages:

    pip install opencv-python-headless
    pip install lz4
    pip install 'boto3>=1.4.8'

Install required components for the Angular website:

    [ Get latest Node.js per https://nodejs.org/en/download/ ]
    cd ~
    curl https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz | tar xJf -
    export PATH=$HOME/node-v10.15.3-linux-x64/bin:$PATH

npm install -g typescript
npm install -g @angular/cli

Cache the interest rate data
----------------------------

Failing to perform this step will result in the full historical yield
curves getting downloaded from the Fed every time a cluster node
starts up.

    ~/aiplanner/ai/cron.daily

Setting up the Ray compute cluster
----------------------------------

This step is optional.

A Ray compute cluster can be used to train the neural network models
on cheaper spot instances rather than on demand instances.

The cluster works most effectively if the head node and worker nodes
are of similar instance families. Otherwise jobs will execute at
uneven rates.

Create a cluster config file:

    cd ~/aiplanner/ai
    cp cluster-example.yaml cluster.yaml
    [edit] cluster.yaml

Rather than have separate cluster head and worker nodes, we are going
to have the AIPlanner host act as the head node. This allows the web
server and jobs that use Ray to share result data directories, but it
requires a little fancy footwork.

First create the cluster IAM role, ssh key pair, and security group.

The easy way to do this is risky as it involves giving full access to
AWS to untrusted code. This may be acceptable if you don't have any
other AWS resources.

If you wish to use the easy risky way, place your AWS credentials in
~/.aws/credentials as described in the boto3 docs.

-----
[default]
aws_access_key_id=<aws_access_key_id>
aws_secret_access_key=<aws_secret_access_key>
-----

    cd ~/aiplanner/ai
    ray up cluster.yaml
    <answer NO to "create new cluster">

This will create the ssh key pair, IAM role, and network security
group.

If you wish to use the difficult but secure method, first use EC2 to
generate an EC2 key pair called ray-autoscaler_us-east-1.pem, and save
it to the .ssh directory. Then create a security group tagged
ray-autoscaler-default that allows all inbound traffic from itself,
inbound ssh from the Internet if desired, and all outbound
traffic. Finally generate an IAM role called ray-autoscaler-v1 with
the following IAM policy atached (in which sg-AAA is replaced by the
ray-autoscaler-default security group):

{"Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowRunInstancesTagged",
            "Effect": "Allow",
            "Action": [
                "ec2:RunInstances"
            ],
            "Resource": "arn:aws:ec2:*:*:instance/*",
            "Condition": {
                "ForAnyValue:StringLike": {
                    "aws:RequestTag/Name": "ray-default-*"
                }
            }
        },
        {
            "Sid": "AllowRunInstances",
            "Effect": "Allow",
            "Action": "ec2:RunInstances",
            "Resource": [
                "arn:aws:ec2:*:*:subnet/*",
                "arn:aws:ec2:*:*:security-group/sg-AAA",
                "arn:aws:ec2:*:*:volume/*",
                "arn:aws:ec2:*:*:network-interface/*",
                "arn:aws:ec2:*::image/*"
            ]
        },
        {
            "Sid": "AllowCreateTagsWhenLaunching",
            "Effect": "Allow",
            "Action": [
                "ec2:CreateTags"
            ],
            "Resource": [
                "arn:aws:ec2:*:*:instance/*",
                "arn:aws:ec2:*:*:volume/*"
            ],
            "Condition": {
                "StringEquals": {
                    "ec2:CreateAction": "RunInstances"
                }
            }
        },
        {
            "Sid": "AllowActionTaggedInstances",
            "Effect": "Allow",
            "Action": [
                "ec2:TerminateInstances",
                "ec2:CreateTags"
            ],
            "Resource": "arn:aws:ec2:*:*:instance/*",
            "Condition": {
                "StringLike": {
                    "ec2:ResourceTag/Name": "ray-default-*"
                }
            }
        },
        {
            "Sid": "AllowDescribeInstances",
            "Effect": "Allow",
            "Action": "ec2:DescribeInstances",
            "Resource": "*"
        }
    ]
}

You may wish to further harden things by restricting the AWS image
that can be used.

Either way the required AWS resources have now been
created. Additional work is required so that the AIPlanner host can
act as the head node.

From the EC2 console perform actions on this host setting the instance
setting IAM role to ray-autoscaler-v1 and networking change security
groups to add ray-autoscaler-default.

For syncing worker node result directories create a link:

    ln -s ~/.ssh/ray-autoscaler_us-east-1.pem ~/ray_bootstrap_key.pem

Add the following line to the "auth" section of cluster.yaml:

----
    ssh_private_key: /home/ubuntu/.ssh/ray-autoscaler_us-east-1.pem
----

And to the "worker_nodes" section add:

----
    SubnetIds:
        - subnet-AAA
    SecurityGroupIds:
        - sg-AAA
----

where the subnet is the subnet in which you wish to create worker
nodes, and the security group identifies ray-autoscaler-default.

If desired, the cluster can now be manually started using:

    cd ~/aiplaner/ai
    source activate tensorflow_p36
    source ./setenv
    ray start --head --redis-port=6379 --autoscaling-config=cluster.yaml

Worker nodes are created when needed, and terminated if idle for a
while.

The cluster can be torn down using:

    cd ~/aiplaner/ai
    ray stop
        # Stops Ray on the head node.
    ray down cluster.yaml
        # Terimanates any running worker nodes.

Setting up environment variables
--------------------------------

Various environment variables need to be set up for production or
development tasks:

    source activate tensorflow_p36

If you have set up a Ray compute cluster indicate you want to use it
during training:

    export RAY_AUTOSCALER=True

Fit the equity volatility model
-------------------------------

A bootstrapped equity return model with GJR-GARCH volatility is
typically used. The model has already been fitted, but if you wish to
fit it yourself perform the following steps.

    cd ~/aiplanner
    mkdir -p data/public
    mkdir -p data/private/ticker
    [download the max time period ticker data for ^SP500TR from
     https://finance.yahoo.com and store it in the just created
     directory as ^SP500TR.csv ]
    cd ~/aiplanner/ai/equity_model
    ./equity_model.py # Ignore the standard output
    cp standardized_residuals.csv ../../data/public

Training the generic nueral network models
------------------------------------------

Training the neural network models (will take approximately 3 days on
two InstanceType c5.24xlarge instances with Ray started with
--num-cpus=60; edit cluster.yaml accordingly):

    cd ~/aiplanner/ai/web
    nohup ./train > /tmp/train.out &

The trained models will be placed in ~/aiplanner-data/models.new .

The models should then be installed:

    cd ~/aiplanner-data
    rm -rf models.old  # Delete prior model backups if required.
    mv models models.old  # Save prior models if any as a backup.
    mv models.new models

Generating required assets (images)
-----------------------------------

Generate the images required for the website:

    cd ~/aiplanner/ai/angular/src/assets.generate
    ./run

Build the website files
-----------------------

Angular provides a single webpage app for interacting with the models.

Angular downloads 350MB of node modules in order to build the website.
These files would slow down the process of synchronizing source trees
when starting up a new Ray cluster node. Therefore if Ray is used it
is recommended that the node modules be stored outside the source
tree:

    mkdir ~/node_modules
    ln -s ~/node_modules ~/aiplanner/ai/angular/node_modules

Build the website:

    export PATH=$HOME/node-v10.15.3-linux-x64/bin:$PATH
    cd ~/aiplanner/ai/angular
    ng build --prod

Install the website:

    cd ~/aiplanner/ai/angular
    ./install

Set up the website
------------------

    sudo apt install apache2
    sudo a2enmod ssl proxy proxy_http
    Ubuntu 18.04:
        sudo apt install python3-certbot-apache
    Ubuntu 16.04:
        sudo add-apt-repository ppa:certbot/certbot
        sudo apt update
        sudo apt install python3-certbot-apache
    sudo certbot --apache certonly
    Email: <you@yourdomain>
    If serving for www.<thisdomain>
        Domain: <thisdomain>
    If serving for a particular host:
        Domain: <thishost.thisdomain>

    Select appropriate <site-ssl.conf> file:
        sudo cp aiplanner/ai/web/sites-examples/<sample-site-ssl.conf> /etc/apache2/sites-available/<site-ssl.conf>
    Edit site.conf appropriately:
        sudo <edit> /etc/apache2/sites-available/<site-ssl.conf>
    sudo a2ensite <site-ssl>
    sudo service apache2 reload

    Repeat installing <site.conf> or <site-ssl.conf> for additional
    sites to be served if desired, so that http://www.<site>/,
    http://<site>/, and https://<site>/ all point to
    https://www.<site>/.

Configure systemd to start the services upon booting
----------------------------------------------------

Set up the systemd config:

    cd ~/aiplanner/ai
    sudo cp aiplanner-apiserver.service /etc/systemd/system/
    sudo systemctl enable aiplanner-apiserver

Start the service up:

    sudo systemctl start aiplanner-apiserver

Setting up cron
---------------

Install crontabs to perform logfile rotation, a daily refresh of the
interest rate yield curves, and a weekly refresh of the fair market
price and volatility.

    crontab -e

----
# m h  dom mon dow   command
MAILTO=<you@yourdomain>
0 0 * * * perl -e '{sleep(rand(1000))}'; ~/aiplanner/ai/cron.daily
0 0 * * 0 perl -e '{sleep(rand(1000))}'; ~/aiplanner/ai/cron.weekly
----

Installing an outbound mailer
-----------------------------

A mail transfer agent is required to provide end users with email
notifications that their long running models have been trained.

    sudo apt install postfix
    sudo dpkg-reconfigure postfix
        Config type: Internet Site
        Site: <thisdomain>
        Root mail: <you@yourdomain>
        Accept mail for: <thisdomain>
        Synchronous updates: no
        Local networks: <leave as is>
        Mailbox size limit: 0
        Address extension: +
        Internet protocols: all
    sudo <edit> /etc/postfix/main.cf
        Change: myhostname = <...>
        To: myhostname = <thisdomain>
    sudo /etc/init.d/postfix reload

You may also need to add an SPF record for the site so messages from
it don't end up in the spam folder. Something like:

    Type: TXT
    Host: @
    Value: v=spf1 ip4:18.206.41.110 ~all
    TTL: 3600

You should also add a MX record so the server can receive and forward
bounce messages addressed to root. Something like:

    Type: MX
    Host: @
    Priority: 1
    Value: ec2-18-206-41-110.compute-1.amazonaws.com
    TTL: 3600

Consult your domain provider for details of how to do these steps.

Finally you may need to create a firewall rule to allow inbound SMTP
connections on port 25. Consult your service provider for details.

Performing site health checks
-----------------------------

Uptime robot, or some other serivce should be used to perform periodic
HTTP GET /healthcheck requests to port 3000 of the production server.
After about 10 seconds, the string "OK" should be returned as the body
to indicate the system appears to be operating normally, any other
result indicates a problem.

Development
-----------

The model server has four functions:
    - respond to the Angular server proxying to it to handle HTTP /api requests
    - execute the run queue to perform long running model training and evaluations
    - purge old results from the directory ~/aiplanner-data
    - respond to HTTP /healthcheck requests

The model server can be run in development as follows:

    cd ~/aiplanner/ai/web
    ./server --admin-email=<you@yourdomain>

On the same machine in another shell window run the Angular server:

    export PATH=$HOME/node-v10.15.3-linux-x64/bin:$PATH
    cd ~/aiplanner/ai/angular
    ng serve --host 0.0.0.0 --public-host <thishost.thisdomain>

Connect to the front end using a browser (need to open port 4200 of
development machine firewall unless doing development on localhost):

    http://<thishost.thisdomain>:4200/
