AIPlanner API Server
====================

This document deals with configuring and running the AIPlanner
api server.

Server requirements
-------------------

The api server can be run out of the box as a docker container on an 2
core 4 thread 16G RAM Amazon m5.xlarge instance. Any Linux
distribution should be able to be used. You should allocate at least
20GB of storage, of which at least 10GB should be free.

/api/infer requests rapidly return a recommended strategy for a given
financial scenario. /api/evaluate requests perform a 30-60 second long
Monte Carlo simulation of the recommended startegy and report its
performance.

By default the system will run 1 concurrent infer job per core, and
number of cores divided by three rounded up concurrent evaluate
jobs. The system needs 5G for each concurrent infer job, and 6G for
each concurrent evaluate job.

Infer is not compute intensive. If you are only performing infer you
can configure num_evaluate_jobs to 0 and run on a 1 core 2 thread 8G
RAM r5.large instance or larger instances of this family.

Evaluate is compute intensive. If you are only performing evaluate you
can configure num_infer_jobs to 0 and run on a 2 core 4 thread 8G RAM
c5.xlarge instance or larger instances of this family. Each evaluate
job normally comprises 3 compute bound processes, so you will get
slightly faster evaluations if you use a 4 core 8 thread 16G RAM
c5.2xlarge instance or larger.

Obtaining access to the api server docker image
-----------------------------------------------

You need to have a docker account ( http://hub.docker.com/ ) and be
granted access to the private gordoni/aiplanner-apiserver repository.

Then on the system where you wish to run the api server:

    docker login
    sudo docker pull gordoni/aiplanner-apiserver
    docker logout

Obtaining the example configuration file and documentation
----------------------------------------------------------

An example configuration file can be obtained using:

    sudo docker run --rm gordoni/aiplanner-apiserver cat aiplanner/ai/aiplanner-example.yaml > aiplanner-example.yaml

API user documentation can be obtained using:

    sudo docker run --rm gordoni/aiplanner-apiserver cat aiplanner/ai/README.api > README.api

Or to obtain the current version of this file:

    sudo docker run --rm gordoni/aiplanner-apiserver cat aiplanner/ai/README.docker > README.docker

Configuring the container
-------------------------

The container is configured using a file called aiplanner.yaml .

    cp aiplanner-example.yaml aiplanner.yaml
    [edit] aiplanner.yaml

If you make changes to the configuration file while the container is
running you will need to stop and restart the container.

Running the container
---------------------

Create an empty AIPlanner email address interest list if desired:

    touch $HOME/aiplanner-data/subscribe.txt

To run the api server at http://localhost:3000/ and print out the
container id:

    sudo docker run -d -t --restart=unless-stopped -p 127.0.0.1:3000:3000 -v $PWD/aiplanner.yaml:/aiplanner.yaml -v $HOME/aiplanner-data/subscribe.txt:/home/aiplanner/aiplanner-data/subscribe.txt gordoni/aiplanner-apiserver

To confirm the container is running:

    sudo docker ps

To test the container:

    curl http://localhost:3000/api/healthcheck

The string "OK" should be output.

If port 80 is firewalled off from the Internet you could replace -p
127.0.0.1:3000:3000 by -p 80:3000 to run the api server on a private
Intranet as http://<my_apiserver_hostname>/ .

If you wish to encrypt traffic to and from the API server you should
use -p 3000:3000 and run a web proxy server externally on the
container host. The Apache web server can be configured as a TLS
supporting proxy by using an Apache configuration file directive like:

    ProxyPass /api http://localhost:3000/api

Terminating the container
-------------------------

Stop the container:

    sudo docker stop <container_id>

Remove it if you like:

    sudo docker rm <container_id>

And if you wish to remove the image:

    sudo docker images
    sudo docker rmi <image_id>
